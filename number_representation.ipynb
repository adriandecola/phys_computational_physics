{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lab 1: Numbers\n",
                "\n",
                "It seems glaringly obvious that numbers are the key element of computational physics. However, physics describes the world by building a hierarchy of *mathematical models* of reality. These models rely often on real numbers, roughly speaking points along an infinite number line:\n",
                "\n",
                "![Number line](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Real_number_line.svg/1000px-Real_number_line.svg.png)\n",
                "\n",
                "Now, of course, as we have discussed, there are numbers, like $\\pi$ or $1/3$ which have an infinite number of decimal digits. We still need to calculate with these numbers, but we cannot fit them in our finite computers. This leads to one of the two main sources of error in computations. \n",
                "\n",
                "### Exercise\n",
                "With a partner, discuss the difference between $\\pi$ and $1/3$, both of which have an infinite number of digits. What is the *key* difference between their decimal expansions?\n",
                "\n",
                "\n",
                "## Motivation\n",
                "Before diving in to learning about number systems and computational representations thereof, let's motivate **why you should care** about it.\n",
                "\n",
                "### Exercise\n",
                "In the cell below, write a function `counter` that takes two arguments, `incr` and `n`. The function should use a `for` loop to add `incr` to zero `n` times. **Don't use multiplication!**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "def counter(incr, n):\n",
                "    #n must be a whole number \n",
                "    num_to_incr = 0\n",
                "    for i in range(n):\n",
                "        num_to_incr += incr\n",
                "    return num_to_incr"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, test your function by setting `incr = 2` and `n=100` and subtracting the analytic answer (that is, calculate it by hand). You should get zero."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "0\n"
                }
            ],
            "source": [
                "analytic_answer = 200 #=2*100\n",
                "test = counter(2,100) - analytic_answer # should be zero\n",
                "print(test)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now do the same thing again, but set `incr = 0.1` and `n=100`. Now, rather than using the analytic answer, use multiplication: `incr*n`. I've provided test code below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "-1.9539925233402755e-14\n"
                }
            ],
            "source": [
                "analytic_answer = 10 #=.1*100\n",
                "test = counter(.1,100) - analytic_answer # should be zero\n",
                "print(test) "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "incr = 0.1\n",
                "n = 100\n",
                "mult_ans = #fill this in\n",
                "test = counter(incr,n) - mult_ans\n",
                "print(test)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Something weird should have happend!**\n",
                "\n",
                "In order to understand what is going on, try the same thing but with `incr = 0.2, 0.3, 0.4, 0.5`. What happens with each case? Can you figure out a pattern? \n",
                "\n",
                "This weirdness is why we need to spend time understanding how numbers work.\n",
                "\n",
                "#### Programming tip\n",
                "Try to write the cell above such that you only need to change a single thing to run the different cases: the value of `incr`. Everything else should just *work*. If you want to get fancy, you could even write another function `test_counter` (or whatever you want to call it) that does everything all at once. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The difference between the value we got from the counter function and the analytically calculated expected value is -3.907985046680551e-14.\nThe difference between the value we got from the counter function and the analytically calculated expected value is 4.973799150320701e-14.\nThe difference between the value we got from the counter function and the analytically calculated expected value is -7.815970093361102e-14.\nThe difference between the value we got from the counter function and the analytically calculated expected value is 0.0.\n"
                }
            ],
            "source": [
                "def test_counter(increases, n):\n",
                "    \"\"\" increases should be a list of all the different values of we want to try increasing by \"\"\"\n",
                "    for incr in increases:\n",
                "        analytical_answer = incr * n\n",
                "        test = counter(incr,n) - analytical_answer # should be zero\n",
                "        print(f\"The difference between the value we got from the counter function and the \" + \\\n",
                "              f\"analytically calculated expected value is {test}.\")\n",
                "\n",
                "# Using the test_counter function\n",
                "increases = [.2, .3, .4, .5]\n",
                "n = 100\n",
                "test_counter(increases, n)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Binary \n",
                "\n",
                "Virtually every computer uses binary to store numbers. A binary number system uses only two values, canonically 0 and 1, in each digit, as opposed to the ten we use in decimal. Very briefly, here is a short table showing the conversion of the first ten integers from decimal to binary:\n",
                "\n",
                "|Decimal|Binary|\n",
                "|-------|------|\n",
                "|00|0000|\n",
                "|01|0001|\n",
                "|02|0010|\n",
                "|03|0011|\n",
                "|04|0100|\n",
                "|05|0101|\n",
                "|06|0110|\n",
                "|07|0111|\n",
                "|08|1000|\n",
                "|09|1001|\n",
                "|10|1010|\n",
                "\n",
                "Each digit of the binary number is called a \"bit\" (\"binary digit\"). Thus, the bit is the smallest unit of computer memory. One byte is 8 bits. \n",
                "\n",
                "Just as an arbitrary number can be expanded in decimal as \n",
                "\n",
                "$$x = \\sum_{i=-\\infty}^{\\infty} \\alpha_i 10^{i},$$\n",
                "\n",
                "an arbitrary number can be expanded in binary as \n",
                "\n",
                "$$x = \\sum_{i=-\\infty}^{\\infty} \\beta_i 2^{i},$$\n",
                "\n",
                "where $\\alpha_i \\ne \\beta_i$, and obviously most of the coefficents are zero.\n",
                "\n",
                "`numpy` provides a function (`np.binary_repr()`) to convert *integers* into their binary represenation. Let's practice a bit by using it. Try changing $n$ below. Try a bunch of numbers to get a feel for how binary works. You might try putting `np.binary_repr()` into a loop."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "'10011110100001010111'"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "n = 649303\n",
                "\n",
                "np.binary_repr(n)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise\n",
                "Create a new code cell below, and see what happens when you try to give a floating point number (e.g. 43.2) to `np.binary_repr()`. Read carefully the output. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "'float' object cannot be interpreted as an integer",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m\u003ccell line: 3\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9.2\u001b[39m\n\u001b[0;32m----\u003e 3\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/usr/lib/python3.10/site-packages/numpy/core/numeric.py:2021\u001b[0m, in \u001b[0;36mbinary_repr\u001b[0;34m(num, width)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2015\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsufficient bit width provided. This behavior \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2016\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill raise an error in the future.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m   2017\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;66;03m# Ensure that num is a Python integer to avoid overflow or unwanted\u001b[39;00m\n\u001b[1;32m   2020\u001b[0m \u001b[38;5;66;03m# casts to floating point.\u001b[39;00m\n\u001b[0;32m-\u003e 2021\u001b[0m num \u001b[38;5;241m=\u001b[39m \u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m (width \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n",
                        "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
                    ]
                }
            ],
            "source": [
                "n = 9.2\n",
                "\n",
                "np.binary_repr(n)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Floating Point Numbers\n",
                "\n",
                "Throughout this class, we will need to work with computer representations of real numbers: we'll be adding, subtracting, dividing, and multiplying them in order to solve complex problems regarding the world. In order to understand everything in the physical universe, we need to cover length scales ranging from the size of the proton, $l_p \\sim 10^{-14}\\ \\mathrm{m}$,\\* to the size of the observable universe, $L_u \\sim 10^{27}\\ \\mathrm{m}$. Taking the ratio of $L_u/l_p \\simeq 10^{41}$, we see there is a factor of $10^{41}$ between the smallest and largest length scales.\n",
                "\n",
                "In order to cover quantities over such a large range of scales, we typically use scientific notation in our paper-and-pencil work, and computers do very much the same thing. Just as in your physics lab courses, you got used to keeping track of only a fixed number of digits of precision. Here, the computer does exactly the same thing. The only tricky part is that the number, which we like to represent in decmial form, is stored in binary. \n",
                "\n",
                "Let's analyze scientific notation, taking a typical value, say the mass of the electron $ m_e = 9.10938356 \\times 10^{-31} \\mathrm{kg}$. \n",
                "\n",
                "We can write this schematically as \n",
                "\n",
                "$$ m_e = (-1)^s\\ m\\ \\times 10^e,$$\n",
                "\n",
                "where $s=0$ is called the sign, $m= 9.10938356$ the mantissa or significant, and $e=-31$ the exponent. \n",
                "\n",
                "Of course, the computer stores the number $m_e$ in binary, so it must be converted. We'll use the notation $N_{10}$ to mean a number $N$ in base 10, and $N_{2}$ to mean a number in base 2. For example $10_{10} = 1010_{2}$. \n",
                "\n",
                "## IEEE 754\n",
                "\n",
                "There are many ways of storing floating point numbers on a computer; we will only describe one: IEEE 754. This is the most widely used standard for representing these numbers. An IEEE 754 number is represented in the following way:\n",
                "\n",
                "$$ x = (-1)^s\\ 1.f\\ \\times 2^{e-B},$$\n",
                "\n",
                "where $s$ is the sign, $f$ is the *fractional part* of the mantissa (note that there is 1 in front), $e$ is the exponent of the number you want to represent, and $B$ is called the *bias*. Note that the total exponent stored in memory $e$  has no sign bit and is thus **always positive**. This explains the need for the bias: if we want to represent actual exponents $p = e -B \u003c 0$, then $B\u003e0$. A floating point number standard that can't hold the mass of an electron is not very useful to scientists. \n",
                "\n",
                "IEEE 754 defines two different kinds of floating point numbers: single and double precision. Single precision floating point numbers are called `float`s and take up 32 bits of memory, and double precision is called `double` and take up 64 bits of memory. **Unfortunately, python doesn't respect this naming convention**, chosing instead to use `float` to mean a 64-bit number, and `float32` to mean a 32-bit number. This is only mildly annoying in practice, since you'll probably never need a 32-bit float after this week. \n",
                "\n",
                "**We'll use 32-bit single precision as our example here, even though you will almost always work in double precision.** A 32 bit `float` uses 1 bit to hold the sign $s$, 8 bits to hold the exponent $e$, and the remaining 23 bits to hold the mantissa. The bias $B = 127$ for single precision.\n",
                "\n",
                "Let's consider the exponent first. With 8 bits, the largest value that can be held is with all 8 digits set to 1, 11111111:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "255"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# convert a binary digit written as a string (that is, in quotes) prefaced with '0b' to decimal integers\n",
                "int('0b11111111',base=2) "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "obviously, the smallest value is 00000000:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "int('0b00000000',base=2) "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "So, $0 \\leq e \\leq 255$. In IEEE 754, $e=0$ and $e=255$ are special, so normal numbers are restricted to $0 \\lt e \\lt 255$. \n",
                "\n",
                "The fractional part of the mantissa is 23 bits wide, plus the 1 we assue leads the mantissa, for a total of 24 digits. So the largest possible mantissa is (remember, this is really a binary *fraction*: 1.11111111111111111111111)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "1.9999998807907104"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "int('0b111111111111111111111111',base=2)*2**-23"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "So, putting these together, the largest digit we can store is "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "3.402823466385289e+38\n"
                }
            ],
            "source": [
                "m = int('0b111111111111111111111111',base=2)*2**-23\n",
                "bias = 127\n",
                "exp = 2**(254-bias)\n",
                "\n",
                "print(\"{:20.15e}\".format(m*exp))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As mentioned above, the case $e = 0$ is a special one. In this case, the 23 mantissa bits represent the entire mantissa, and the leading digit is zero (instead of one, as is usual). Also, the total stored exponent will be -126. So, the smallest number is thus"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "1.401298464324817e-45\n"
                }
            ],
            "source": [
                "m = int('0b000000000000000000000001',base=2)*2**-23\n",
                "exp = 2**(-126)\n",
                "\n",
                "print(\"{:20.15e}\".format(m*exp))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        }
    ]
}
